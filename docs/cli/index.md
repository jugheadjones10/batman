# CLI Tools Overview

Batman provides a comprehensive set of command-line tools for training, inference, benchmarking, and data management.

## Tool Categories

### ðŸŽ“ Training & Inference
- **[train](train.md)** - Train RF-DETR models on Batman projects or COCO datasets
- **[inference](inference.md)** - Run inference on images and videos with tracking support

### âš¡ Performance Testing
- **[benchmark_latency](benchmark-latency.md)** - Measure inference latency with detailed statistics
- **[compare_latency](compare-latency.md)** - Compare benchmark results across GPUs

### ðŸŽ¬ Video Tools
- **[create_latency_video](create-latency-video.md)** - Create latency-delayed visualization videos
- **[create_sidebyside_video](create-sidebyside-video.md)** - Create side-by-side comparison videos

### ðŸ“¦ Data Management
- **[importer](importer.md)** - Import datasets from Roboflow or COCO Zoo
- **[classes](classes.md)** - List, rename, and merge object classes

## Common Usage Patterns

### Model Specification

Most tools accept one of three ways to specify a model:

```bash
# Option 1: By checkpoint path
--checkpoint path/to/model.pth

# Option 2: By run name (auto-finds checkpoint)
--run rfdetr_h100_20260120_105925

# Option 3: Use latest run
--latest
```

### Project Structure

Tools expect this directory structure:

```
runs/
  â””â”€â”€ <run_name>/
      â”œâ”€â”€ best.pth              # Best checkpoint
      â”œâ”€â”€ checkpoint_best.pth   # Alternative name
      â”œâ”€â”€ training_config.json  # Training configuration
      â””â”€â”€ results.json          # Training results

data/projects/
  â””â”€â”€ <project_name>/
      â”œâ”€â”€ project.json          # Project metadata
      â”œâ”€â”€ videos/               # Video files
      â”œâ”€â”€ frames/               # Extracted frames
      â””â”€â”€ labels/               # Annotations
```

### Device Selection

Most tools support automatic device detection:

```bash
# Auto-detect best device (CUDA > MPS > CPU)
--device auto

# Force specific device
--device cuda
--device mps
--device cpu
```

### Output Directories

Default output locations:

| Tool | Default Output |
|------|----------------|
| Training | `runs/rfdetr_run/` |
| Inference | `inference_results/` |
| Benchmarking | `benchmark_results/` |
| Dataset Export | `datasets/rfdetr_coco/` |

## Installation

All CLI tools are available after installing Batman:

```bash
# Install with uv
uv sync

# Run tools
uv run python -m cli.train --help
uv run python -m cli.inference --help
```

## Common Arguments

### Help and Version

```bash
# Get help for any tool
python -m cli.<tool> --help

# Get help for subcommands
python -m cli.importer --help
python -m cli.importer roboflow --help
```

### Confidence Thresholds

For inference and benchmarking:

```bash
# Detection confidence (default: 0.5)
--confidence 0.7

# Tracking threshold (default: 0.25)
--track-thresh 0.3
```

### Model Sizes

When specifying model architecture:

```bash
# For training
--model base    # RF-DETR-Base
--model large   # RF-DETR-Large

# Also supports
--model nano    # RF-DETR-Nano
--model small   # RF-DETR-Small
--model medium  # RF-DETR-Medium
```

## Quick Examples

### Train a Model

```bash
uv run python -m cli.train \
  --project data/projects/MyProject \
  --epochs 50 \
  --batch-size 8 \
  --model base
```

### Run Inference

```bash
uv run python -m cli.inference \
  --run my_training_run \
  --input video.mp4 \
  --track \
  --confidence 0.6
```

### Benchmark Performance

```bash
uv run python -m cli.benchmark_latency \
  --run my_training_run \
  --video test_video.mp4 \
  --runs 100
```

### Import Data

```bash
uv run python -m cli.importer coco \
  --project data/projects/NewProject \
  --create \
  --classes person car bicycle
```

## Tips & Best Practices

### 1. Use Run Names for Convenience

Instead of specifying full checkpoint paths, use run names:

```bash
# Easier to type and remember
--run rfdetr_h100_20260120_105925

# Instead of
--checkpoint runs/rfdetr_h100_20260120_105925/best.pth
```

### 2. Enable Optimization for Inference

Most inference tools support model optimization:

```bash
# Enable automatic optimization (default)
python -m cli.inference --run my_run --input video.mp4

# Disable if you encounter issues
python -m cli.inference --run my_run --input video.mp4 --no-optimize
```

### 3. Use Tracking for Videos

Enable tracking for better temporal consistency:

```bash
python -m cli.inference \
  --run my_run \
  --input video.mp4 \
  --track \
  --track-buffer 30
```

### 4. Save JSON for Analysis

Keep JSON outputs for programmatic analysis:

```bash
# Inference outputs both visualizations and JSON
python -m cli.inference --run my_run --input video.mp4
# Saves: detected_video.mp4 + detections.json
```

### 5. Specify Classes for Clarity

Load class names from projects or specify manually:

```bash
# From project
--project data/projects/MyProject

# Manual specification
--classes "person,car,bicycle"
```

## Next Steps

- **[Training Guide](../guides/training.md)** - Learn the complete training workflow
- **[Inference Guide](../guides/inference.md)** - Master inference techniques
- **[SLURM Scripts](../scripts/index.md)** - Run jobs on HPC clusters
- **[Benchmarking Guide](../guides/benchmarking.md)** - Performance testing strategies
